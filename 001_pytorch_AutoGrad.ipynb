{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVOgY1372HAAjFTYJFbadz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mustafa-AbdulRazek/NLP-Transformers/blob/master/001_pytorch_AutoGrad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v9Npqza10HNj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "labels = torch.rand(1, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9oOPxCz0VgR",
        "outputId": "2d6785f6-91c3-4b7b-b6d3-b3db8415dbba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 83.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(data)"
      ],
      "metadata": {
        "id": "AYPIzmGW0njf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = (prediction - labels).sum()\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "45GAOWTx1Iq-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ],
      "metadata": {
        "id": "m7KFeoYy0L6y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim.step()"
      ],
      "metadata": {
        "id": "VN5IkRw-2YwD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Differentiation in Autograd"
      ],
      "metadata": {
        "id": "FIz6vdbT27uo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create two tensors just to take a look at how autograd collects gradients.\n",
        "\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "metadata": {
        "id": "LXxvLt-V0L8-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then create another tensor Q from a and b.\n",
        "# Q = 3a^3 = b^2\n",
        "\n",
        "Q = 3*a**3 - b**2"
      ],
      "metadata": {
        "id": "oOj6H85AOJHv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume a and b to be params of an NN, and Q to be the error.\n",
        "# In NN training, we want gradients of the error.\n",
        "\n",
        "external_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=external_grad)"
      ],
      "metadata": {
        "id": "8LkM_7TyOj-t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if collected gradients are correct\n",
        "\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGV4lY14PtN3",
        "outputId": "47863829-93a8-442b-e8cf-63cc1153b491"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, 5)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8dAOGrGP48g",
        "outputId": "a48fc583-1400-401a-8035-0c6677df13db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3421, 0.6238, 0.4024, 0.2161, 0.7112],\n",
              "        [0.8367, 0.1234, 0.0099, 0.3951, 0.8252],\n",
              "        [0.1315, 0.6146, 0.4437, 0.7350, 0.7663],\n",
              "        [0.0560, 0.5275, 0.0302, 0.4980, 0.0032],\n",
              "        [0.7017, 0.5863, 0.7491, 0.1555, 0.7265]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad=True)\n",
        "\n",
        "a = x + y\n",
        "print(f\"Does `a` require gradients? : {a.requires_grad}\")\n",
        "b = x + z\n",
        "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnqiSr4X0L_I",
        "outputId": "be688354-58e8-4059-9733-93682e3e412a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does `a` require gradients? : False\n",
            "Does `b` require gradients?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets freeze resnet params, e.g. for fine-tuning for example.\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# freeze all params in the Net\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "S87PlOWD0MCs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tune the model on 10 labels\n",
        "# in resnet, the clf is the last linear layer model.fc\n",
        "\n",
        "model.fc = nn.Linear(512, 10)\n",
        "\n",
        "# now all params of the model are frozen,\n",
        "# the only params that compute gradients are weights and bias of model.fc"
      ],
      "metadata": {
        "id": "Lmu6QwrI48eF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize only the classifier\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
        "\n",
        "\n",
        "# Notice although we register all the parameters in the optimizer,\n",
        "# the only parameters that are computing gradients\n",
        "# (and hence updated in gradient descent) are the weights and bias of the classifier."
      ],
      "metadata": {
        "id": "cJsVPN315g9M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uzXAs_QV5ywC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}